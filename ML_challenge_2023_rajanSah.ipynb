{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Challenge WS 2022/23\n",
    "\n",
    "#### Task:\n",
    "\n",
    "Your Task is to train a clickbait filter to classify clickbait articles by their headline. You freely decide how to prepare the data and which ML model to use for classification.\n",
    "\n",
    "The challenge is considered passed if your model performs better than our baseline (a simple classifier; F1 ~0.89). Report at least the F1 score of your classifier. Your model will be evaluated using a hold out dataset. Please prepare a script so your trained model can be evaluated with this dataset.\n",
    "\n",
    "#### Dataset:\n",
    "\n",
    "The data consists of two files, a text file with clickbait headlines and one with headlines from news sources. The hold out dataset is organized the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submitted by rajan sah (tunika -1622936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#still empji remove \n",
    "#type short and fast texting so spelling mistake \n",
    "#use differnet ngram in countvectorizer \n",
    "\n",
    "#2.tf idf \n",
    "\n",
    "#drop duplicates\n",
    "#gauss naives \n",
    "#reduce the feature while vectorizing to see if it improves \n",
    "#ngram in countvectorizer -if use ngram -1 , data would be too much \n",
    "#if memory error when increase range in ngram, use max_feature =5000\n",
    "#try different legth of feature \n",
    "#tfidf -\n",
    "\n",
    "###use word2vec -coding part \n",
    "#how to convert sentence into vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with open('clickbait_no') as f:\n",
    "#     lines = [line.rstrip() for line in f]\n",
    "\n",
    "# lines[0:10]\n",
    "\n",
    "# type(lines)\n",
    "# #lines[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading file from clickbait no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickbait no file\n",
    "f = open('clickbait_no', \"r\")\n",
    "\n",
    "lines = [line.rstrip() for line in f]\n",
    "\n",
    "text = f.readlines()\n",
    "#print(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Resto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14460</th>\n",
       "      <td>UK's Liverpool FC unveils plans for new stadium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14461</th>\n",
       "      <td>Doughnut on display in Springfield, New Zealand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14462</th>\n",
       "      <td>Colombian soldiers killed by rebel group</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14463</th>\n",
       "      <td>UEFA president Platini confirms Euro 2012 to b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>Rod Woodson Tries to Stay Grounded Amid Hall o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14465 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      Soccer Provides Oasis in Mexican City Ravaged ...      0\n",
       "1      Five police officers injured in Naples protest...      0\n",
       "2      International experts probe deadly Ebola Resto...      0\n",
       "3      UK elections: Gordon Brown offers resignation ...      0\n",
       "4         Eric Bogosian on writing and the creative urge      0\n",
       "...                                                  ...    ...\n",
       "14460    UK's Liverpool FC unveils plans for new stadium      0\n",
       "14461    Doughnut on display in Springfield, New Zealand      0\n",
       "14462           Colombian soldiers killed by rebel group      0\n",
       "14463  UEFA president Platini confirms Euro 2012 to b...      0\n",
       "14464  Rod Woodson Tries to Stay Grounded Amid Hall o...      0\n",
       "\n",
       "[14465 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df from file \n",
    "import pandas as pd\n",
    "\n",
    "clickbaitNodf= pd.DataFrame(lines)\n",
    "\n",
    "\n",
    "clickbaitNodf.columns=['content']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clickbaitNodf['label']=0\n",
    "\n",
    "\n",
    "clickbaitNodf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reading file from clickbait yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickbait yes file\n",
    "f = open('clickbait_yes', \"r\")\n",
    "\n",
    "lines = [line.rstrip() for line in f]\n",
    "\n",
    "text = f.readlines()\n",
    "#print(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Guys Try Tinder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael B. Jordan Got Laid The Fuck Out While ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's The Most Fucked Up Thing You've Done On...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How Far Would You Make It In The Hunger Games</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If Matthew Gray Gubler's Tweets Were Motivatio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You El...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0                                        Guys Try Tinder      1\n",
       "1      Michael B. Jordan Got Laid The Fuck Out While ...      1\n",
       "2      What's The Most Fucked Up Thing You've Done On...      1\n",
       "3          How Far Would You Make It In The Hunger Games      1\n",
       "4      If Matthew Gray Gubler's Tweets Were Motivatio...      1\n",
       "...                                                  ...    ...\n",
       "14330  This Dad Just Shut It Down By Videobombing His...      1\n",
       "14331  21 Gorgeous Drinking Accessories To Get You El...      1\n",
       "14332  23 Cheap Upgrades That Will Actually Increase ...      1\n",
       "14333  Indian Girls Revealed What Kind Of Porn They L...      1\n",
       "14334  This Image Test Will Determine What You Want F...      1\n",
       "\n",
       "[14335 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df from file \n",
    "import pandas as pd\n",
    "\n",
    "clickbaityesdf= pd.DataFrame(lines)\n",
    "\n",
    "\n",
    "clickbaityesdf.columns=['content']\n",
    "\n",
    "\n",
    "clickbaityesdf['label']=1\n",
    "\n",
    "\n",
    "clickbaityesdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge both df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Resto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You El...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      Soccer Provides Oasis in Mexican City Ravaged ...      0\n",
       "1      Five police officers injured in Naples protest...      0\n",
       "2      International experts probe deadly Ebola Resto...      0\n",
       "3      UK elections: Gordon Brown offers resignation ...      0\n",
       "4         Eric Bogosian on writing and the creative urge      0\n",
       "...                                                  ...    ...\n",
       "14330  This Dad Just Shut It Down By Videobombing His...      1\n",
       "14331  21 Gorgeous Drinking Accessories To Get You El...      1\n",
       "14332  23 Cheap Upgrades That Will Actually Increase ...      1\n",
       "14333  Indian Girls Revealed What Kind Of Porn They L...      1\n",
       "14334  This Image Test Will Determine What You Want F...      1\n",
       "\n",
       "[28800 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#print('After merging:')\n",
    "finaldfclickbait=pd.concat([clickbaitNodf, clickbaityesdf], axis=0)\n",
    "\n",
    "\n",
    "finaldfclickbait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #lenght of dataframe \n",
    "\n",
    "# print(len(finaldfclickbait))\n",
    "\n",
    "# print(len(clickbaitNodf)+len(clickbaityesdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14335, 14465]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pos_neg_count=[clickbaityesdf['label'].count(),clickbaitNodf['label'].count()]\n",
    "\n",
    "pos_neg_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "piechart = plt.pie(pos_neg_count,labels=[\"positive\",\"negative\"], autopct ='%1.1f%%', colors = ['green', 'red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 60]\n",
      "[nltk_data]     Operation timed out>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 60] Operation\n",
      "[nltk_data]     timed out>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "try:\n",
    "    nltk.data.find('punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# def remove_stopwords(text):\n",
    "#     output = \"\"\n",
    "#     text = text.split(\" \")\n",
    "#     for word in text:\n",
    "#         if word not in stopwords.words(\"english\"):\n",
    "#             output = output + \" \" + word\n",
    "#         else:\n",
    "#             output = text\n",
    "#     return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(text):\n",
    "    return ' '.join(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def remove_tags(text):\n",
    "#     text = re.sub('<[^>]*>','',text)\n",
    "#     #text=re.sub(r'[^\\w]', '', text)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# def stemming(text):\n",
    "#     porter = PorterStemmer()\n",
    "#     stems = [porter.stem(word) for word in text.split()]\n",
    "#     return \" \".join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessor(text):\n",
    "#     text = tokenize(text)\n",
    "#     #text = remove_stopwords(text)\n",
    "#     text = remove_tags(text)\n",
    "#     text = stemming(text)\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldfclickbait1 = finaldfclickbait.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Resto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You El...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They L...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "0      Soccer Provides Oasis in Mexican City Ravaged ...      0\n",
       "1      Five police officers injured in Naples protest...      0\n",
       "2      International experts probe deadly Ebola Resto...      0\n",
       "3      UK elections: Gordon Brown offers resignation ...      0\n",
       "4         Eric Bogosian on writing and the creative urge      0\n",
       "...                                                  ...    ...\n",
       "14330  This Dad Just Shut It Down By Videobombing His...      1\n",
       "14331  21 Gorgeous Drinking Accessories To Get You El...      1\n",
       "14332  23 Cheap Upgrades That Will Actually Increase ...      1\n",
       "14333  Indian Girls Revealed What Kind Of Porn They L...      1\n",
       "14334  This Image Test Will Determine What You Want F...      1\n",
       "\n",
       "[28800 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldfclickbait1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #work more on preprocessing data to improve model \n",
    "# pd.options.display.max_colwidth = 2000\n",
    "# finaldfclickbait1.iloc[45,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1\n",
    "convert into lower case\n",
    "\n",
    "content2 is transformed column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finaldfclickbait1['content2']= finaldfclickbait1['content'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content     Aid to Poor Nations Rises, but Even More Is Asked\n",
       "label                                                       0\n",
       "content2    aid to poor nations rises, but even more is asked\n",
       "Name: 45, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldfclickbait1.iloc[45,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(finaldfclickbait1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2- remove tags \n",
    "# step 3 -remove prounciation\n",
    "# step 4 -stopwords \n",
    "# step 4 -stemming ,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "step 2 -remove tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_tags(text):\n",
    "    text=re.sub('<[^>]*>','',text)\n",
    "    text = re.sub('<[^>]*>','',text)\n",
    "    #text=re.sub(r'[^\\w]', '', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "    text = re.sub('\\[.*?\\]', ' ', text)\n",
    "    #text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('“','',text)\n",
    "    text = re.sub('”','',text)\n",
    "    text = re.sub('’','',text)\n",
    "    text = re.sub('–','',text)\n",
    "    text = re.sub('‘','',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "finaldfclickbait1['content2'] = finaldfclickbait1['content2'].apply(lambda text: remove_tags(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged by Drug War</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer provides oasis in mexican city ravaged by drug war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest over new garbage tip</td>\n",
       "      <td>0</td>\n",
       "      <td>five police officers injured in naples protest over new garbage tip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Reston virus outbreak in Philippine pigs</td>\n",
       "      <td>0</td>\n",
       "      <td>international experts probe deadly ebola reston virus outbreak in philippine pigs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition</td>\n",
       "      <td>0</td>\n",
       "      <td>uk elections: gordon brown offers resignation to secure labour-liberal coalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "      <td>eric bogosian on writing and the creative urge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His Daughters Dancing</td>\n",
       "      <td>1</td>\n",
       "      <td>this dad just shut it down by videobombing his daughters dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You Elegantly Wasted</td>\n",
       "      <td>1</td>\n",
       "      <td>21 gorgeous drinking accessories to get you elegantly wasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase The Value of Your Home</td>\n",
       "      <td>1</td>\n",
       "      <td>23 cheap upgrades that will actually increase the value of your home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You</td>\n",
       "      <td>1</td>\n",
       "      <td>indian girls revealed what kind of porn they like, and their choices may surprise you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want From A Relationship</td>\n",
       "      <td>1</td>\n",
       "      <td>this image test will determine what you want from a relationship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     content  \\\n",
       "0                                  Soccer Provides Oasis in Mexican City Ravaged by Drug War   \n",
       "1                        Five police officers injured in Naples protest over new garbage tip   \n",
       "2          International experts probe deadly Ebola Reston virus outbreak in Philippine pigs   \n",
       "3           UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition   \n",
       "4                                             Eric Bogosian on writing and the creative urge   \n",
       "...                                                                                      ...   \n",
       "14330                       This Dad Just Shut It Down By Videobombing His Daughters Dancing   \n",
       "14331                           21 Gorgeous Drinking Accessories To Get You Elegantly Wasted   \n",
       "14332                   23 Cheap Upgrades That Will Actually Increase The Value of Your Home   \n",
       "14333  Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You   \n",
       "14334                       This Image Test Will Determine What You Want From A Relationship   \n",
       "\n",
       "       label  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "...      ...   \n",
       "14330      1   \n",
       "14331      1   \n",
       "14332      1   \n",
       "14333      1   \n",
       "14334      1   \n",
       "\n",
       "                                                                                    content2  \n",
       "0                                  soccer provides oasis in mexican city ravaged by drug war  \n",
       "1                        five police officers injured in naples protest over new garbage tip  \n",
       "2          international experts probe deadly ebola reston virus outbreak in philippine pigs  \n",
       "3           uk elections: gordon brown offers resignation to secure labour-liberal coalition  \n",
       "4                                             eric bogosian on writing and the creative urge  \n",
       "...                                                                                      ...  \n",
       "14330                       this dad just shut it down by videobombing his daughters dancing  \n",
       "14331                           21 gorgeous drinking accessories to get you elegantly wasted  \n",
       "14332                   23 cheap upgrades that will actually increase the value of your home  \n",
       "14333  indian girls revealed what kind of porn they like, and their choices may surprise you  \n",
       "14334                       this image test will determine what you want from a relationship  \n",
       "\n",
       "[28800 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 2000\n",
    "finaldfclickbait1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3: remove punctuation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punct(text):\n",
    "    return text.translate(str.maketrans('','',string.punctuation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "finaldfclickbait1['content2'] = finaldfclickbait1['content2'].apply(lambda text: remove_punct(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged by Drug War</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer provides oasis in mexican city ravaged by drug war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest over new garbage tip</td>\n",
       "      <td>0</td>\n",
       "      <td>five police officers injured in naples protest over new garbage tip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Reston virus outbreak in Philippine pigs</td>\n",
       "      <td>0</td>\n",
       "      <td>international experts probe deadly ebola reston virus outbreak in philippine pigs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition</td>\n",
       "      <td>0</td>\n",
       "      <td>uk elections gordon brown offers resignation to secure labourliberal coalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "      <td>eric bogosian on writing and the creative urge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His Daughters Dancing</td>\n",
       "      <td>1</td>\n",
       "      <td>this dad just shut it down by videobombing his daughters dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You Elegantly Wasted</td>\n",
       "      <td>1</td>\n",
       "      <td>21 gorgeous drinking accessories to get you elegantly wasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase The Value of Your Home</td>\n",
       "      <td>1</td>\n",
       "      <td>23 cheap upgrades that will actually increase the value of your home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You</td>\n",
       "      <td>1</td>\n",
       "      <td>indian girls revealed what kind of porn they like and their choices may surprise you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want From A Relationship</td>\n",
       "      <td>1</td>\n",
       "      <td>this image test will determine what you want from a relationship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     content  \\\n",
       "0                                  Soccer Provides Oasis in Mexican City Ravaged by Drug War   \n",
       "1                        Five police officers injured in Naples protest over new garbage tip   \n",
       "2          International experts probe deadly Ebola Reston virus outbreak in Philippine pigs   \n",
       "3           UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition   \n",
       "4                                             Eric Bogosian on writing and the creative urge   \n",
       "...                                                                                      ...   \n",
       "14330                       This Dad Just Shut It Down By Videobombing His Daughters Dancing   \n",
       "14331                           21 Gorgeous Drinking Accessories To Get You Elegantly Wasted   \n",
       "14332                   23 Cheap Upgrades That Will Actually Increase The Value of Your Home   \n",
       "14333  Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You   \n",
       "14334                       This Image Test Will Determine What You Want From A Relationship   \n",
       "\n",
       "       label  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "...      ...   \n",
       "14330      1   \n",
       "14331      1   \n",
       "14332      1   \n",
       "14333      1   \n",
       "14334      1   \n",
       "\n",
       "                                                                                   content2  \n",
       "0                                 soccer provides oasis in mexican city ravaged by drug war  \n",
       "1                       five police officers injured in naples protest over new garbage tip  \n",
       "2         international experts probe deadly ebola reston virus outbreak in philippine pigs  \n",
       "3            uk elections gordon brown offers resignation to secure labourliberal coalition  \n",
       "4                                            eric bogosian on writing and the creative urge  \n",
       "...                                                                                     ...  \n",
       "14330                      this dad just shut it down by videobombing his daughters dancing  \n",
       "14331                          21 gorgeous drinking accessories to get you elegantly wasted  \n",
       "14332                  23 cheap upgrades that will actually increase the value of your home  \n",
       "14333  indian girls revealed what kind of porn they like and their choices may surprise you  \n",
       "14334                      this image test will determine what you want from a relationship  \n",
       "\n",
       "[28800 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldfclickbait1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #step 4 -textblob getting full form of words like fyi -become for your info \n",
    "# from textblob import TextBlob\n",
    "# def acronomy(text):\n",
    "#     textBlb=TextBlob(text)\n",
    "#     textBlb.correct().string()\n",
    "#     return textBlb\n",
    "\n",
    "##remove emoji \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# finaldfclickbait1['content2'] = finaldfclickbait1['content2'].apply(lambda text: acronomy(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_spacy(text):\n",
    "    tokenword=[]\n",
    "    nlp=spacy.load(\"en_core_web_sm\")\n",
    "    doc1=nlp(text)\n",
    "    for token in doc1:\n",
    "        tokenword.append(token)\n",
    "    return tokenword\n",
    "\n",
    "#word_tokenize(word)---use this once except split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words(\"english\"):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x=new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "finaldfclickbait1['content2'] = finaldfclickbait1['content2'].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>content2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soccer Provides Oasis in Mexican City Ravaged by Drug War</td>\n",
       "      <td>0</td>\n",
       "      <td>soccer provides oasis  mexican city ravaged  drug war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Five police officers injured in Naples protest over new garbage tip</td>\n",
       "      <td>0</td>\n",
       "      <td>five police officers injured  naples protest  new garbage tip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>International experts probe deadly Ebola Reston virus outbreak in Philippine pigs</td>\n",
       "      <td>0</td>\n",
       "      <td>international experts probe deadly ebola reston virus outbreak  philippine pigs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition</td>\n",
       "      <td>0</td>\n",
       "      <td>uk elections gordon brown offers resignation  secure labourliberal coalition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eric Bogosian on writing and the creative urge</td>\n",
       "      <td>0</td>\n",
       "      <td>eric bogosian  writing   creative urge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14330</th>\n",
       "      <td>This Dad Just Shut It Down By Videobombing His Daughters Dancing</td>\n",
       "      <td>1</td>\n",
       "      <td>dad  shut    videobombing  daughters dancing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>21 Gorgeous Drinking Accessories To Get You Elegantly Wasted</td>\n",
       "      <td>1</td>\n",
       "      <td>21 gorgeous drinking accessories  get  elegantly wasted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14332</th>\n",
       "      <td>23 Cheap Upgrades That Will Actually Increase The Value of Your Home</td>\n",
       "      <td>1</td>\n",
       "      <td>23 cheap upgrades   actually increase  value   home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14333</th>\n",
       "      <td>Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You</td>\n",
       "      <td>1</td>\n",
       "      <td>indian girls revealed  kind  porn  like   choices may surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14334</th>\n",
       "      <td>This Image Test Will Determine What You Want From A Relationship</td>\n",
       "      <td>1</td>\n",
       "      <td>image test  determine   want   relationship</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     content  \\\n",
       "0                                  Soccer Provides Oasis in Mexican City Ravaged by Drug War   \n",
       "1                        Five police officers injured in Naples protest over new garbage tip   \n",
       "2          International experts probe deadly Ebola Reston virus outbreak in Philippine pigs   \n",
       "3           UK elections: Gordon Brown offers resignation to secure Labour-Liberal coalition   \n",
       "4                                             Eric Bogosian on writing and the creative urge   \n",
       "...                                                                                      ...   \n",
       "14330                       This Dad Just Shut It Down By Videobombing His Daughters Dancing   \n",
       "14331                           21 Gorgeous Drinking Accessories To Get You Elegantly Wasted   \n",
       "14332                   23 Cheap Upgrades That Will Actually Increase The Value of Your Home   \n",
       "14333  Indian Girls Revealed What Kind Of Porn They Like, And Their Choices May Surprise You   \n",
       "14334                       This Image Test Will Determine What You Want From A Relationship   \n",
       "\n",
       "       label  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "...      ...   \n",
       "14330      1   \n",
       "14331      1   \n",
       "14332      1   \n",
       "14333      1   \n",
       "14334      1   \n",
       "\n",
       "                                                                              content2  \n",
       "0                                soccer provides oasis  mexican city ravaged  drug war  \n",
       "1                        five police officers injured  naples protest  new garbage tip  \n",
       "2      international experts probe deadly ebola reston virus outbreak  philippine pigs  \n",
       "3         uk elections gordon brown offers resignation  secure labourliberal coalition  \n",
       "4                                               eric bogosian  writing   creative urge  \n",
       "...                                                                                ...  \n",
       "14330                                     dad  shut    videobombing  daughters dancing  \n",
       "14331                          21 gorgeous drinking accessories  get  elegantly wasted  \n",
       "14332                              23 cheap upgrades   actually increase  value   home  \n",
       "14333                  indian girls revealed  kind  porn  like   choices may surprise   \n",
       "14334                                      image test  determine   want   relationship  \n",
       "\n",
       "[28800 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldfclickbait1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert into vectors. one way of doing it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. x_train and y_train from  the given datasets \n",
    "\n",
    "2. x_test and y_test from new datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data into train and test without using vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to test data is being stored in x_test and all the value here in given datset it for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#another way for splitting not using vector values \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    finaldfclickbait1.content2.values, \n",
    "    finaldfclickbait1.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=finaldfclickbait1.label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#type(X_train)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179     1\n",
       "2243     0\n",
       "7240     0\n",
       "9614     1\n",
       "2930     1\n",
       "        ..\n",
       "9075     1\n",
       "14247    0\n",
       "2458     1\n",
       "13227    0\n",
       "1508     1\n",
       "Name: label, Length: 23040, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countvectorizer\n",
    "count = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words = 'english', binary=True)\n",
    "X_train = count.fit_transform(X_train) \n",
    "X_test  = count.transform(X_test)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<23040x20872 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136328 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      2893\n",
      "           1       0.88      0.91      0.89      2867\n",
      "\n",
      "    accuracy                           0.89      5760\n",
      "   macro avg       0.89      0.89      0.89      5760\n",
      "weighted avg       0.89      0.89      0.89      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a Decision Tree model object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisitc -this is the solution for this challenge gives such a highest result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9505208333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.93      0.97      0.95      2893\n",
      "         pos       0.97      0.93      0.95      2867\n",
      "\n",
      "    accuracy                           0.95      5760\n",
      "   macro avg       0.95      0.95      0.95      5760\n",
      "weighted avg       0.95      0.95      0.95      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_classifier = LogisticRegression(max_iter=1000)\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gradient boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83      2893\n",
      "           1       0.96      0.64      0.77      2867\n",
      "\n",
      "    accuracy                           0.81      5760\n",
      "   macro avg       0.84      0.81      0.80      5760\n",
      "weighted avg       0.84      0.81      0.80      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.07      0.13      2893\n",
      "           1       0.51      1.00      0.68      2867\n",
      "\n",
      "    accuracy                           0.53      5760\n",
      "   macro avg       0.75      0.53      0.40      5760\n",
      "weighted avg       0.76      0.53      0.40      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "clf = KNeighborsClassifier(n_neighbors = 10, metric = 'euclidean')\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  soccer provides oasis  mexican city ravaged  drug war\n",
       "1                          five police officers injured  naples protest  new garbage tip\n",
       "2        international experts probe deadly ebola reston virus outbreak  philippine pigs\n",
       "3           uk elections gordon brown offers resignation  secure labourliberal coalition\n",
       "4                                                 eric bogosian  writing   creative urge\n",
       "                                              ...                                       \n",
       "14330                                       dad  shut    videobombing  daughters dancing\n",
       "14331                            21 gorgeous drinking accessories  get  elegantly wasted\n",
       "14332                                23 cheap upgrades   actually increase  value   home\n",
       "14333                    indian girls revealed  kind  porn  like   choices may surprise \n",
       "14334                                        image test  determine   want   relationship\n",
       "Name: content2, Length: 28800, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=finaldfclickbait1.content2\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "14330    1\n",
       "14331    1\n",
       "14332    1\n",
       "14333    1\n",
       "14334    1\n",
       "Name: label, Length: 28800, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=finaldfclickbait1.label\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9598958333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.96      0.96      0.96      2893\n",
      "         pos       0.96      0.96      0.96      2867\n",
      "\n",
      "    accuracy                           0.96      5760\n",
      "   macro avg       0.96      0.96      0.96      5760\n",
      "weighted avg       0.96      0.96      0.96      5760\n",
      "\n",
      "Accuracy: 0.9797743055555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.98      0.98      0.98     11572\n",
      "         pos       0.98      0.98      0.98     11468\n",
      "\n",
      "    accuracy                           0.98     23040\n",
      "   macro avg       0.98      0.98      0.98     23040\n",
      "weighted avg       0.98      0.98      0.98     23040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bayes_classifier = MultinomialNB()\n",
    "bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=['neg','pos']))\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_train)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "print(classification_report(y_train, y_pred, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tf-id for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1, 3), \n",
    "                        use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words = 'english', max_features = 2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way for splitting  using vector values \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    finaldfclickbait1.content2.values, \n",
    "    finaldfclickbait1.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=finaldfclickbait1.label\n",
    ")\n",
    "\n",
    "X_train = tfidf.fit_transform(X_train) \n",
    "X_test  = tfidf.transform(X_test)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.93      0.95      0.94      2893\n",
      "         pos       0.94      0.92      0.93      2867\n",
      "\n",
      "    accuracy                           0.93      5760\n",
      "   macro avg       0.93      0.93      0.93      5760\n",
      "weighted avg       0.93      0.93      0.93      5760\n",
      "\n",
      "Accuracy: 0.9439236111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.95      0.94     11572\n",
      "         pos       0.95      0.94      0.94     11468\n",
      "\n",
      "    accuracy                           0.94     23040\n",
      "   macro avg       0.94      0.94      0.94     23040\n",
      "weighted avg       0.94      0.94      0.94     23040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bayes_classifier = MultinomialNB()\n",
    "bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=['neg','pos']))\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_train)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "print(classification_report(y_train, y_pred, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      2893\n",
      "           1       0.91      0.91      0.91      2867\n",
      "\n",
      "    accuracy                           0.91      5760\n",
      "   macro avg       0.91      0.91      0.91      5760\n",
      "weighted avg       0.91      0.91      0.91      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23040,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "\n",
    "#split data \n",
    "\n",
    "#another way for splitting not using vector values \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    finaldfclickbait1.content2.values, \n",
    "    finaldfclickbait1.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=finaldfclickbait1.label\n",
    ")\n",
    "\n",
    "#vectors = EmbeddingTransformer('/media/glove/eng.kv', aggregation='sum')\n",
    "\n",
    "vectors = EmbeddingTransformer('glove')\n",
    "\n",
    "#vectorize it \n",
    "X_train = vectors.transform(X_train)\n",
    "X_test  = vectors.transform(X_test)\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23040,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.23155698,  0.6437    , -0.2379622 , ..., -0.20002799,\n",
       "        -0.30629402, -0.28967   ],\n",
       "       [-0.85152835,  0.14975667,  0.05137334, ...,  0.29627165,\n",
       "        -0.6048667 , -0.58466935],\n",
       "       [-0.06775143,  0.5330706 , -0.36396003, ...,  0.6905543 ,\n",
       "        -0.14614442, -0.3156843 ],\n",
       "       ...,\n",
       "       [-0.0313895 ,  0.19652376,  0.33502123, ..., -0.00581487,\n",
       "        -0.52158815, -0.12729746],\n",
       "       [ 0.28790748,  0.01580213, -0.34669712, ..., -0.47573227,\n",
       "        -1.0155455 ,  0.0627965 ],\n",
       "       [-0.27491936,  0.40164798, -0.22884402, ..., -0.47526422,\n",
       "         0.5278624 ,  0.06067682]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.42342886,  0.07064229,  0.37989125, ...,  0.05550301,\n",
       "        -0.02550858, -0.11156715],\n",
       "       [-0.12243921,  0.6557192 , -0.9446301 , ..., -0.44127172,\n",
       "        -0.881957  , -0.29297116],\n",
       "       [-0.2450988 ,  0.03977199, -0.92898196, ..., -0.789326  ,\n",
       "        -0.12465   , -0.16720079],\n",
       "       ...,\n",
       "       [-0.15038222,  0.42197523,  0.37512857, ...,  0.29439008,\n",
       "        -0.2874611 , -0.06316044],\n",
       "       [-0.40914622,  0.64259803, -0.6382634 , ...,  0.067836  ,\n",
       "        -0.54017   , -0.441689  ],\n",
       "       [ 0.04796714,  0.49753717,  0.20103857, ..., -0.0848157 ,\n",
       "         0.15594001, -0.10536855]], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9307291666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.93      0.93      0.93      2893\n",
      "         pos       0.93      0.93      0.93      2867\n",
      "\n",
      "    accuracy                           0.93      5760\n",
      "   macro avg       0.93      0.93      0.93      5760\n",
      "weighted avg       0.93      0.93      0.93      5760\n",
      "\n",
      "Accuracy: 0.9334635416666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.94      0.93      0.93     11572\n",
      "         pos       0.93      0.93      0.93     11468\n",
      "\n",
      "    accuracy                           0.93     23040\n",
      "   macro avg       0.93      0.93      0.93     23040\n",
      "weighted avg       0.93      0.93      0.93     23040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logisitic on embedding \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_classifier = LogisticRegression(max_iter=1000)\n",
    "logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg_classifier.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=['neg','pos']))\n",
    "\n",
    "y_pred = logreg_classifier.predict(X_train)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "print(classification_report(y_train, y_pred, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22936,)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #nearest neighbour \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     finaldfclickbait1.content2.values, \n",
    "#     finaldfclickbait1.label, \n",
    "#     test_size=0.2, # 20% samples will go to test dataset\n",
    "#     random_state=2022,\n",
    "#     stratify=finaldfclickbait1.label\n",
    "# )\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "# KNN_classifier.fit(X_train,y_train)\n",
    "# y_pred = KNN_classifier.predict(X_test)\n",
    "\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "# print(classification_report(y_test, y_pred, target_names=['neg','pos']))\n",
    "\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "# print(classification_report(y_train, y_pred, target_names=['neg','pos']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "finaldfclickbait1['vector'] = finaldfclickbait1['content2'].apply(lambda text: nlp(text).vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldfclickbait1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train before reshaping:  (23040,)\n",
      "Shape of X_test before reshaping:  (5760,)\n",
      "Shape of X_train after reshaping:  (23040, 300)\n",
      "Shape of X_test after reshaping:  (5760, 300)\n"
     ]
    }
   ],
   "source": [
    "#with vectorized \n",
    "#split data \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    finaldfclickbait1.vector.values, \n",
    "    finaldfclickbait1.label, \n",
    "    test_size=0.2, # 20% samples will go to test dataset\n",
    "    random_state=2022,\n",
    "    stratify=finaldfclickbait1.label\n",
    ")\n",
    "\n",
    "print(\"Shape of X_train before reshaping: \", X_train.shape)\n",
    "print(\"Shape of X_test before reshaping: \", X_test.shape)\n",
    "\n",
    "\n",
    "X_train_2d = np.stack(X_train)\n",
    "X_test_2d =  np.stack(X_test)\n",
    "\n",
    "print(\"Shape of X_train after reshaping: \", X_train_2d.shape)\n",
    "print(\"Shape of X_test after reshaping: \", X_test_2d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2893\n",
      "           1       0.82      0.84      0.83      2867\n",
      "\n",
      "    accuracy                           0.83      5760\n",
      "   macro avg       0.83      0.83      0.83      5760\n",
      "weighted avg       0.83      0.83      0.83      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#1. creating a Decision Tree model object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      2893\n",
      "           1       0.87      0.89      0.88      2867\n",
      "\n",
      "    accuracy                           0.88      5760\n",
      "   macro avg       0.88      0.88      0.88      5760\n",
      "weighted avg       0.88      0.88      0.88      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#does not work with count vectorizer \n",
    "\n",
    "#doing scaling because Negative values will not pass into Naive Bayes models\n",
    "scaler = MinMaxScaler()                                         \n",
    "scaled_train_embed = scaler.fit_transform(X_train_2d)\n",
    "scaled_test_embed = scaler.transform(X_test_2d)\n",
    "\n",
    "#1. creating a MultinomialNB model object \n",
    "clf = MultinomialNB()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(scaled_train_embed , y_train) \n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(scaled_test_embed)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      2893\n",
      "           1       0.93      0.91      0.92      2867\n",
      "\n",
      "    accuracy                           0.92      5760\n",
      "   macro avg       0.92      0.92      0.92      5760\n",
      "weighted avg       0.92      0.92      0.92      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      2893\n",
      "           1       0.92      0.91      0.92      2867\n",
      "\n",
      "    accuracy                           0.92      5760\n",
      "   macro avg       0.92      0.92      0.92      5760\n",
      "weighted avg       0.92      0.92      0.92      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90      2893\n",
      "           1       0.86      0.97      0.91      2867\n",
      "\n",
      "    accuracy                           0.90      5760\n",
      "   macro avg       0.91      0.90      0.90      5760\n",
      "weighted avg       0.91      0.90      0.90      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "clf = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "clf.fit(X_train_2d, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "y_pred = clf.predict(X_test_2d)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8986111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.95      0.85      0.89      2893\n",
      "         pos       0.86      0.95      0.90      2867\n",
      "\n",
      "    accuracy                           0.90      5760\n",
      "   macro avg       0.90      0.90      0.90      5760\n",
      "weighted avg       0.90      0.90      0.90      5760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#nearest neighbour \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KNN_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "KNN_classifier.fit(X_train_2d,y_train)\n",
    "y_pred = KNN_classifier.predict(X_test_2d)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=['neg','pos']))\n",
    "\n",
    "# y_pred = logreg_classifier.predict(X_train)\n",
    "# print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "# print(classification_report(y_train, y_pred, target_names=['neg','pos']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for the given datsets by hold up data \n",
    "\n",
    "\n",
    "# from testing on given datsets \"MultinomialNB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"/Users/rajansah/Documents/msc/3rdSem/ml4nlu/assignment/ML_challenge/clickbait_hold_X.csv\",header=None)\n",
    "\n",
    "type(test_data)\n",
    "\n",
    "test_data.columns=['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['content2']= test_data['content'].apply(lambda x: x.lower())\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "test_data['content2'] = test_data['content2'].apply(lambda text: remove_tags(text))\n",
    "\n",
    "import string\n",
    "test_data['content2'] = test_data['content2'].apply(lambda text: remove_punct(text))\n",
    "\n",
    "import string\n",
    "test_data['content2'] = test_data['content2'].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize \n",
    "X_train=finaldfclickbait1.content2\n",
    "count = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', stop_words = 'english', binary=True)\n",
    "\n",
    "X_train = count.fit_transform(X_train) \n",
    "\n",
    "y_train = finaldfclickbait1.label.values\n",
    "\n",
    "X_test  = count.transform(test_data.content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 23315)\n",
      "(3200, 23315)\n",
      "(28800,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#the best model when using datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200,)\n"
     ]
    }
   ],
   "source": [
    "# predict labels \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bayes_classifier = MultinomialNB()\n",
    "bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_test)\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "\n",
    "###put label in dataframe \n",
    "\n",
    "test_data['label']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>content2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How To Make The Ultimate Spaghetti With Red Sauce</td>\n",
       "      <td>make  ultimate spaghetti  red sauce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soviet human rights activist Yelena Bonner dies aged 88</td>\n",
       "      <td>soviet human rights activist yelena bonner dies aged 88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone Calculated How Much Money Jim Spent Pranking Dwight On \"The Office\" And It's Crazy</td>\n",
       "      <td>someone calculated  much money jim spent pranking dwight   office   crazy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Demonstrators clash with police in Algeria after slum protest</td>\n",
       "      <td>demonstrators clash  police  algeria  slum protest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Color Quiz Will Tell You Which Husky Should Be Your BFF</td>\n",
       "      <td>color quiz  tell   husky    bff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>WHO: H1N1 influenza virus still a pandemic</td>\n",
       "      <td>h1n1 influenza virus still  pandemic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>No More Surprises as Marist Women Assume Higher Profile</td>\n",
       "      <td>surprises  marist women assume higher profile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>Japan raises severity level of crisis; efforts to cool damaged nuclear power plant continue</td>\n",
       "      <td>japan raises severity level  crisis efforts  cool damaged nuclear power plant continue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>14 Women Who Pushed Their Boob Potential To The Limit</td>\n",
       "      <td>14 women  pushed  boob potential   limit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>18 Texts Your Mom Definitely Sent You During College</td>\n",
       "      <td>18 texts  mom definitely sent   college</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          content  \\\n",
       "0                                               How To Make The Ultimate Spaghetti With Red Sauce   \n",
       "1                                         Soviet human rights activist Yelena Bonner dies aged 88   \n",
       "2      Someone Calculated How Much Money Jim Spent Pranking Dwight On \"The Office\" And It's Crazy   \n",
       "3                                   Demonstrators clash with police in Algeria after slum protest   \n",
       "4                                    This Color Quiz Will Tell You Which Husky Should Be Your BFF   \n",
       "...                                                                                           ...   \n",
       "3195                                                   WHO: H1N1 influenza virus still a pandemic   \n",
       "3196                                      No More Surprises as Marist Women Assume Higher Profile   \n",
       "3197  Japan raises severity level of crisis; efforts to cool damaged nuclear power plant continue   \n",
       "3198                                        14 Women Who Pushed Their Boob Potential To The Limit   \n",
       "3199                                         18 Texts Your Mom Definitely Sent You During College   \n",
       "\n",
       "                                                                                    content2  \\\n",
       "0                                                        make  ultimate spaghetti  red sauce   \n",
       "1                                    soviet human rights activist yelena bonner dies aged 88   \n",
       "2                  someone calculated  much money jim spent pranking dwight   office   crazy   \n",
       "3                                         demonstrators clash  police  algeria  slum protest   \n",
       "4                                                            color quiz  tell   husky    bff   \n",
       "...                                                                                      ...   \n",
       "3195                                                    h1n1 influenza virus still  pandemic   \n",
       "3196                                           surprises  marist women assume higher profile   \n",
       "3197  japan raises severity level  crisis efforts  cool damaged nuclear power plant continue   \n",
       "3198                                                14 women  pushed  boob potential   limit   \n",
       "3199                                                 18 texts  mom definitely sent   college   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  \n",
       "...     ...  \n",
       "3195      0  \n",
       "3196      0  \n",
       "3197      0  \n",
       "3198      0  \n",
       "3199      1  \n",
       "\n",
       "[3200 rows x 3 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##checking accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28800, 23315)\n",
      "(28800,)\n",
      "(28800,)\n",
      "Accuracy: 0.9794444444444445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.98      0.98      0.98     14465\n",
      "         pos       0.98      0.98      0.98     14335\n",
      "\n",
      "    accuracy                           0.98     28800\n",
      "   macro avg       0.98      0.98      0.98     28800\n",
      "weighted avg       0.98      0.98      0.98     28800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(y_pred.shape)\n",
    "\n",
    "\n",
    "bayes_classifier = MultinomialNB()\n",
    "bayes_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = bayes_classifier.predict(X_train)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_train, y_pred)))\n",
    "print(classification_report(y_train, y_pred, target_names=['neg','pos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result into csv \n",
    "\n",
    "\n",
    "#delete content2 since its transformed columns \n",
    "\n",
    "test_data = test_data.drop('content2', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How To Make The Ultimate Spaghetti With Red Sauce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Soviet human rights activist Yelena Bonner dies aged 88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Someone Calculated How Much Money Jim Spent Pranking Dwight On \"The Office\" And It's Crazy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Demonstrators clash with police in Algeria after slum protest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This Color Quiz Will Tell You Which Husky Should Be Your BFF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>WHO: H1N1 influenza virus still a pandemic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>No More Surprises as Marist Women Assume Higher Profile</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>Japan raises severity level of crisis; efforts to cool damaged nuclear power plant continue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>14 Women Who Pushed Their Boob Potential To The Limit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>18 Texts Your Mom Definitely Sent You During College</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          content  \\\n",
       "0                                               How To Make The Ultimate Spaghetti With Red Sauce   \n",
       "1                                         Soviet human rights activist Yelena Bonner dies aged 88   \n",
       "2      Someone Calculated How Much Money Jim Spent Pranking Dwight On \"The Office\" And It's Crazy   \n",
       "3                                   Demonstrators clash with police in Algeria after slum protest   \n",
       "4                                    This Color Quiz Will Tell You Which Husky Should Be Your BFF   \n",
       "...                                                                                           ...   \n",
       "3195                                                   WHO: H1N1 influenza virus still a pandemic   \n",
       "3196                                      No More Surprises as Marist Women Assume Higher Profile   \n",
       "3197  Japan raises severity level of crisis; efforts to cool damaged nuclear power plant continue   \n",
       "3198                                        14 Women Who Pushed Their Boob Potential To The Limit   \n",
       "3199                                         18 Texts Your Mom Definitely Sent You During College   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  \n",
       "...     ...  \n",
       "3195      0  \n",
       "3196      0  \n",
       "3197      0  \n",
       "3198      0  \n",
       "3199      1  \n",
       "\n",
       "[3200 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store result in csv file \n",
    "\n",
    "\n",
    "test_data.to_csv('/Users/rajansah/Documents/msc/3rdSem/ml4nlu/assignment/ML_challenge/MLCHALLENGERESULTWITHLABELnew.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions?\n",
    "\n",
    "[kuglerk@uni-trier.de](mailto:kuglerk@uni-trier.de?subject=ML%20Challenge%20NLU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "974742b9e3f84bbfc2ab858fce40e48c160687419b819993149cbe09d34e2b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
